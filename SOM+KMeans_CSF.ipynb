{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc9136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "np.random.seed(1)\n",
    "from minisom import MiniSom\n",
    "from sklearn.cluster import KMeans\n",
    "import itertools\n",
    "import gc\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.cm as cm\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ad996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from minisom import MiniSom\n",
    "import bisect\n",
    "from itertools import combinations\n",
    "\n",
    "class ConsensusCluster:\n",
    "    \"\"\"\n",
    "      Implementation of Consensus clustering, following the paper\n",
    "      https://link.springer.com/content/pdf/10.1023%2FA%3A1023949509487.pdf\n",
    "      Args:\n",
    "        * cluster -> clustering class\n",
    "                    needs fit_predict method called with parameter n_clusters\n",
    "        * L -> smallest number of clusters to try\n",
    "        * K -> biggest number of clusters to try\n",
    "        * H -> number of resamplings for each cluster number\n",
    "        * resample_proportion -> percentage to sample\n",
    "        * Mk -> consensus matrices for each k (shape =(K,data.shape[0],data.shape[0]))\n",
    "                (NOTE: every consensus matrix is retained, like specified in the paper)\n",
    "        * Ak -> area under CDF for each number of clusters \n",
    "                (see paper: section 3.3.1. Consensus distribution.)\n",
    "        * deltaK -> changes in ares under CDF\n",
    "                (see paper: section 3.3.1. Consensus distribution.)\n",
    "        * self.bestK -> number of clusters that was found to be best\n",
    "      \"\"\"\n",
    "\n",
    "    def __init__(self, cluster, L, K, H, resample_proportion=0.5):\n",
    "        assert 0 <= resample_proportion <= 1, \"proportion has to be between 0 and 1\"\n",
    "        self.cluster_ = cluster\n",
    "        self.resample_proportion_ = resample_proportion\n",
    "        self.L_ = L\n",
    "        self.K_ = K\n",
    "        self.H_ = H\n",
    "        self.Mk = None\n",
    "        self.Ak = None\n",
    "        self.deltaK = None\n",
    "        self.bestK = None\n",
    "\n",
    "    def _internal_resample(self, data, proportion):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          * data -> (examples,attributes) format\n",
    "          * proportion -> percentage to sample\n",
    "        \"\"\"\n",
    "        resampled_indices = np.random.choice(\n",
    "            range(data.shape[0]), size=int(data.shape[0]*proportion), replace=False)\n",
    "        return resampled_indices, data[resampled_indices, :]\n",
    "\n",
    "    def fit(self, data, verbose=False):\n",
    "        \"\"\"\n",
    "        Fits a consensus matrix for each number of clusters\n",
    "        Args:\n",
    "          * data -> (examples,attributes) format\n",
    "          * verbose -> should print or not\n",
    "        \"\"\"\n",
    "        Mk = np.zeros((self.K_-self.L_, data.shape[0], data.shape[0]))\n",
    "        Is = np.zeros((data.shape[0],)*2)\n",
    "        for k in range(self.L_, self.K_):  # for each number of clusters\n",
    "            i_ = k-self.L_\n",
    "            if verbose:\n",
    "                print(\"At k = %d, aka. iteration = %d\" % (k, i_))\n",
    "            for h in range(self.H_):  # resample H times\n",
    "                if verbose:\n",
    "                    print(\"\\tAt resampling h = %d, (k = %d)\" % (h, k))\n",
    "                resampled_indices, resample_data = self._internal_resample(\n",
    "                    data, self.resample_proportion_)\n",
    "                Mh = self.cluster_(n_clusters=k).fit_predict(resample_data)\n",
    "                # find indexes of elements from same clusters with bisection\n",
    "                # on sorted array => this is more efficient than brute force search\n",
    "                id_clusts = np.argsort(Mh)\n",
    "                sorted_ = Mh[id_clusts]\n",
    "                for i in range(k):  # for each cluster\n",
    "                    ia = bisect.bisect_left(sorted_, i)\n",
    "                    ib = bisect.bisect_right(sorted_, i)\n",
    "                    is_ = id_clusts[ia:ib]\n",
    "                    ids_ = np.array(list(combinations(is_, 2))).T\n",
    "                    # sometimes only one element is in a cluster (no combinations)\n",
    "                    if ids_.size != 0:\n",
    "                        Mk[i_, ids_[0], ids_[1]] += 1\n",
    "                # increment counts\n",
    "                ids_2 = np.array(list(combinations(resampled_indices, 2))).T\n",
    "                Is[ids_2[0], ids_2[1]] += 1\n",
    "            Mk[i_] /= Is+1e-8  # consensus matrix\n",
    "            # Mk[i_] is upper triangular (with zeros on diagonal), we now make it symmetric\n",
    "            Mk[i_] += Mk[i_].T\n",
    "            Mk[i_, range(data.shape[0]), range(\n",
    "                data.shape[0])] = 1  # always with self\n",
    "            Is.fill(0)  # reset counter\n",
    "        self.Mk = Mk\n",
    "        # fits areas under the CDFs\n",
    "        self.Ak = np.zeros(self.K_-self.L_)\n",
    "        for i, m in enumerate(Mk):\n",
    "            hist, bins = np.histogram(m.ravel(), density=True)\n",
    "            self.Ak[i] = np.sum(h*(b-a)\n",
    "                             for b, a, h in zip(bins[1:], bins[:-1], np.cumsum(hist)))\n",
    "        # fits differences between areas under CDFs\n",
    "        self.deltaK = np.array([(Ab-Aa)/Aa if i > 2 else Aa\n",
    "                                for Ab, Aa, i in zip(self.Ak[1:], self.Ak[:-1], range(self.L_, self.K_-1))])\n",
    "        self.bestK = np.argmax(self.deltaK) + \\\n",
    "            self.L_ if self.deltaK.size > 0 else self.L_\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predicts on the consensus matrix, for best found cluster number\n",
    "        \"\"\"\n",
    "        assert self.Mk is not None, \"First run fit\"\n",
    "        return self.cluster_(n_clusters=self.bestK).fit_predict(\n",
    "            1-self.Mk[self.bestK-self.L_])\n",
    "\n",
    "    def predict_data(self, data):\n",
    "        \"\"\"\n",
    "        Predicts on the data, for best found cluster number\n",
    "        Args:\n",
    "          * data -> (examples,attributes) format \n",
    "        \"\"\"\n",
    "        assert self.Mk is not None, \"First run fit\"\n",
    "        return self.cluster_(n_clusters=self.bestK).fit_predict(\n",
    "            data)\n",
    "    \n",
    "    def set_bestK(k):\n",
    "        self.bestK = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_info = pd.read_excel('/work/zg78/brain-flow-data/All_demographic_data_abridged dm.xlsx')\n",
    "dem_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_info['binary_druguse'] = dem_info['Group'].map({'dual':1, 'coc':1, 'mj':0, 'non':0})\n",
    "dem_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(dem_info['binary_druguse'].values, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_path = '/work/zg78/brain-flow-data/CSF_viable_npy/'\n",
    "\n",
    "# cell_events_per_subset = 10000\n",
    "\n",
    "x_train = np.load(npy_path+os.listdir(npy_path)[0])\n",
    "# subsample_idx = np.random.choice(x_train.shape[0], cell_events_per_subset, replace=False)\n",
    "x_train_sub = x_train\n",
    "\n",
    "for f in os.listdir(npy_path)[1:]:\n",
    "    x_train_ = np.load(npy_path+f)\n",
    "\n",
    "#     subsample_idx_ = np.random.choice(x_train_.shape[0], cell_events_per_subset, replace=False)\n",
    "    x_train_sub_ = x_train_       \n",
    "    x_train_sub = np.concatenate((x_train_sub, x_train_sub_), axis=0)\n",
    "\n",
    "mean_ = np.mean(x_train_sub, axis=0)\n",
    "std_ = np.std(x_train_sub, axis=0)\n",
    "x_train_sub = (x_train_sub - mean_) / std_\n",
    "\n",
    "print(x_train_sub.shape)\n",
    "\n",
    "np.random.shuffle(x_train_sub)\n",
    "\n",
    "size = 100\n",
    "som = MiniSom(size, size, x_train_sub.shape[1],\n",
    "              neighborhood_function='bubble', sigma=2, learning_rate=.8, topology='hexagonal',\n",
    "              random_seed=42)\n",
    "# som = MiniSom(size, size, x_train_sub.shape[1],\n",
    "#               neighborhood_function='triangle', sigma=2, learning_rate=.8, topology='hexagonal',\n",
    "#               random_seed=42)\n",
    "\n",
    "som.pca_weights_init(x_train_sub)\n",
    "som.train_random(x_train_sub, 10000, verbose=True)\n",
    "weights = som.get_weights()\n",
    "flatten_weights = weights.reshape(size*size, x_train_sub.shape[1])\n",
    "\n",
    "cluster_ = ConsensusCluster(KMeans, 6, 25, 100, resample_proportion=0.9)\n",
    "cluster_.fit(flatten_weights, True) # fitting SOM weights into clustering algorithm\n",
    "print(flatten_weights.shape, weights.shape)\n",
    "best_k = cluster_.bestK\n",
    "print('K:', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# os.mkdir('/work/zg78/som_kmeans_save/')\n",
    "# with open('/work/zg78/som_kmeans_save/som.pkl', 'wb') as somf:\n",
    "#     pkl.dump(som, somf)\n",
    "    \n",
    "# with open('/work/zg78/som_kmeans_save/km.pkl', 'wb') as kmf:\n",
    "#     pkl.dump(cluster_, kmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('/work/zg78/som_kmeans_save/som.pkl', 'rb') as somf:\n",
    "    som = pkl.load(somf)\n",
    "    \n",
    "with open('/work/zg78/som_kmeans_save/km.pkl', 'rb') as kmf:\n",
    "    cluster_ = pkl.load(kmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_path = '/work/zg78/brain-flow-data/CSF_viable_npy/'\n",
    "\n",
    "x_train = np.load(npy_path+os.listdir(npy_path)[0])\n",
    "x_train_sub = x_train\n",
    "\n",
    "for f in os.listdir(npy_path)[1:]:\n",
    "    x_train_ = np.load(npy_path+f)\n",
    "\n",
    "    x_train_sub_ = x_train_\n",
    "    x_train_sub = np.concatenate((x_train_sub, x_train_sub_), axis=0)\n",
    "\n",
    "mean_ = np.mean(x_train_sub, axis=0)\n",
    "std_ = np.std(x_train_sub, axis=0)\n",
    "x_train_sub = (x_train_sub - mean_) / std_\n",
    "\n",
    "size = 100\n",
    "weights = som.get_weights()\n",
    "flatten_weights = weights.reshape(size*size, x_train_sub.shape[1])\n",
    "\n",
    "best_k = cluster_.bestK\n",
    "print('K:', best_k)\n",
    "flatten_class = cluster_.predict_data(flatten_weights)\n",
    "map_class = flatten_class.reshape(size, size)\n",
    "print(np.unique(map_class, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5170e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "    \n",
    "def get_row_rst(som_, map_class, xx):\n",
    "    winner = som_.winner(xx)\n",
    "    c = map_class[winner] # from the location info get cluster info\n",
    "    return c\n",
    "\n",
    "def get_classes(som_, x_test, k):\n",
    "\n",
    "    x_test = (x_test - np.mean(x_test, axis=0)) / np.std(x_test, axis=0)\n",
    "    \n",
    "    pool_args = []\n",
    "    for i in range(len(x_test)):\n",
    "        xx = x_test[i, :]\n",
    "        pool_args.append([som, map_class, xx])\n",
    "    \n",
    "    pool = Pool()\n",
    "    label_list = pool.starmap(get_row_rst, pool_args)\n",
    "    pool.terminate()\n",
    "\n",
    "    label_counts = [0]*k\n",
    "    label, counts = np.unique(np.asarray(label_list), return_counts=True)\n",
    "    for i in range(len(label)):\n",
    "        label_counts[label[i]] = counts[i]\n",
    "\n",
    "    return np.asarray(label_counts) / x_test.shape[0]\n",
    "\n",
    "npy_path = '/work/zg78/brain-flow-data/CSF_viable_npy/'\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for fidx, splits in enumerate(kf.split(os.listdir(npy_path))):\n",
    "    \n",
    "    xs_train = []\n",
    "    ys_train = []\n",
    "    scores_train = []\n",
    "    xs_val = []\n",
    "    ys_val = []\n",
    "    scores_val = []\n",
    "\n",
    "    covars_train = []\n",
    "    covars_val = []\n",
    "    \n",
    "    train_idx, val_idx = splits\n",
    "    train_f = [os.listdir(npy_path)[i] for i in train_idx]\n",
    "    val_f = [os.listdir(npy_path)[i] for i in val_idx]\n",
    "    \n",
    "    for f in tqdm(train_f):\n",
    "        subject = int(f.split(' ')[0])\n",
    "        if subject == 1001: subject = 2001\n",
    "        x = np.load(npy_path + f)\n",
    "        x = (x - mean_) / std_\n",
    "        rst = get_classes(som, x, best_k)\n",
    "        y = dem_info.loc[dem_info['PID'] == subject]['binary_druguse'].values\n",
    "        xs_train.append(rst)\n",
    "        ys_train.append(y[0])\n",
    "        \n",
    "    \n",
    "    for f in tqdm(val_f):\n",
    "        subject = int(f.split(' ')[0])\n",
    "        if subject == 1001: subject = 2001\n",
    "        x = np.load(npy_path + f)\n",
    "        x = (x - mean_) / std_\n",
    "        rst = get_classes(som, x, best_k)\n",
    "        y = dem_info.loc[dem_info['PID'] == subject]['binary_druguse'].values\n",
    "        xs_val.append(rst)\n",
    "        ys_val.append(y[0])\n",
    "    \n",
    "    xs_train = np.asarray(xs_train)\n",
    "    ys_train = np.asarray(ys_train)\n",
    "    xs_val = np.asarray(xs_val)\n",
    "    ys_val = np.asarray(ys_val)\n",
    "    \n",
    "    print(xs_train.shape, ys_train.shape, xs_val.shape, ys_val.shape)\n",
    "\n",
    "    np.save('/work/zg78/som_folds/CSF100_X_train_{}.npy'.format(fidx), xs_train)\n",
    "    np.save('/work/zg78/som_folds/CSF100_y_train_{}.npy'.format(fidx), ys_train)\n",
    "    np.save('/work/zg78/som_folds/CSF100_X_val_{}.npy'.format(fidx), xs_val)\n",
    "    np.save('/work/zg78/som_folds/CSF100_y_val_{}.npy'.format(fidx), ys_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_rst(som_, map_class, xx):\n",
    "    winner = som_.winner(xx)\n",
    "    c = map_class[winner] # from the location info get cluster info\n",
    "    return c\n",
    "\n",
    "x = np.load(npy_path+os.listdir(npy_path)[0])\n",
    "for f in tqdm(os.listdir(npy_path)[1:]):\n",
    "    x_ = np.load(npy_path+f)\n",
    "    x = np.concatenate((x, x_))\n",
    "x = (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
    "print(x.shape)\n",
    "cluster_labels = []\n",
    "for row in tqdm(x):\n",
    "    cluster = get_row_rst(som, map_class, row)\n",
    "    cluster_labels.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199bdd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "np.random.seed(1)\n",
    "subsample_idx = np.random.choice(x.shape[0], 5000, replace=False)\n",
    "cluster_labels = np.asarray(cluster_labels)\n",
    "print(np.unique(cluster_labels))\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_x = tsne.fit_transform(x[subsample_idx])\n",
    "# print(np.unique(cluster_labels))\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "plt.scatter(\n",
    "    x=tsne_x[:, 0], y=tsne_x[:, 1],\n",
    "    c=cluster_labels[subsample_idx],\n",
    "    alpha=0.8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd49078",
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_info = pd.read_excel('/work/zg78/brain-flow-data/BRAIN NP+WCST_Merged 2020-0528_abridged dm.xlsx')\n",
    "cog_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb81637",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_info_nadropped = dem_info.dropna()\n",
    "cog_info_nadropped = cog_info.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c15399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dem_info(categories):\n",
    "    dem_infos = []\n",
    "    for cat in categories:\n",
    "        info = dem_info.loc[dem_info['PID'] == subject][cat].values[0]\n",
    "        dem_infos.append(info)\n",
    "    \n",
    "    return dem_infos\n",
    "\n",
    "dem_info_categories = ['cigdyc_r', 'agey_np', 'edu_np', 'Years.HIV', 'Years.Treat', 'MDE_lifetime', 'CoMorbid']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for fidx, splits in enumerate(kf.split(os.listdir(npy_path))):\n",
    "\n",
    "    covars_train = []\n",
    "    covars_val = []\n",
    "    \n",
    "    cog_train = []\n",
    "    cog_val = []\n",
    "\n",
    "    train_idx, val_idx = splits\n",
    "    train_f = [os.listdir(npy_path)[i] for i in train_idx]\n",
    "    val_f = [os.listdir(npy_path)[i] for i in val_idx]\n",
    "    \n",
    "    for f in tqdm(train_f):\n",
    "        subject = int(f.split(' ')[0])\n",
    "        if subject == 1001: subject = 2001\n",
    "        dem_infos = get_dem_info(dem_info_categories)\n",
    "        cog_status = cog_info.loc[cog_info['subject'] == subject]['Global_T_impair'].values[0]\n",
    "        covars_train.append(dem_infos)\n",
    "        cog_train.append(cog_status)\n",
    "    \n",
    "    for f in tqdm(val_f):\n",
    "        subject = int(f.split(' ')[0])\n",
    "        if subject == 1001: subject = 2001\n",
    "        dem_infos = get_dem_info(dem_info_categories)\n",
    "        cog_status = cog_info.loc[cog_info['subject'] == subject]['Global_T_impair'].values[0]\n",
    "        covars_val.append(dem_infos)\n",
    "        cog_val.append(cog_status)\n",
    "    \n",
    "    covars_train = np.asarray(covars_train)\n",
    "    covars_val = np.asarray(covars_val)\n",
    "    \n",
    "#     covar_mean_ = np.mean(covars_train, axis=0)\n",
    "#     covar_std_ = np.std(covars_train, axis=0)\n",
    "#     covars_train = (covars_train - covar_mean_) / covar_std_\n",
    "#     covars_val = (covars_val - covar_mean_) / covar_std_\n",
    "    \n",
    "    cog_train = np.asarray(cog_train)\n",
    "    cog_val = np.asarray(cog_val)\n",
    "    \n",
    "    np.save('/work/zg78/som_folds/covar_train_{}.npy'.format(fidx), covars_train)\n",
    "    np.save('/work/zg78/som_folds/cog_train_{}.npy'.format(fidx), cog_train)\n",
    "    np.save('/work/zg78/som_folds/covar_val_{}.npy'.format(fidx), covars_val)\n",
    "    np.save('/work/zg78/som_folds/cog_val_{}.npy'.format(fidx), cog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41842260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
