{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36998b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "import numpy as np\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import LeakyReLU, Conv2D, MaxPool2D, UpSampling2D, Input, Lambda, BatchNormalization, Activation, Dense, AveragePooling2D, MaxPooling2D, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tensorflow.keras import backend as k\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn import preprocessing\n",
    "from keras.regularizers import l1,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e591ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_model():\n",
    "    model_input = Input((10000, 27, 1))\n",
    "\n",
    "    # first convolution layer\n",
    "    model_output = Conv2D(3, kernel_size=(1, 27), activation=None)(model_input)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "    # sceond convolution layer\n",
    "    model_output = Conv2D(3, (1, 1), activation=None)(model_output)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "    # pooling layer\n",
    "    model_output = AveragePooling2D(pool_size=(10000, 1))(model_output)\n",
    "    model_output = Flatten()(model_output)\n",
    "\n",
    "    # Dense layer\n",
    "    model_output = Dense(3, activation=None)(model_output)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "    # output layer\n",
    "    model_output = Dense(1, activation=None)(model_output)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"sigmoid\")(model_output)\n",
    "    \n",
    "    model = Model(model_input, model_output)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.load_weights('saved_weights.hdf5')\n",
    "        \n",
    "#     for idx, layer in enumerate(model.layers):\n",
    "#         print(idx, layer.name, layer.trainable)\n",
    "        \n",
    "    return model\n",
    "        \n",
    "\n",
    "def current_model(ori_model):\n",
    "    model_input = Input((1000, 25, 1))\n",
    "\n",
    "    # first convolution layer\n",
    "    model_output = Conv2D(3, kernel_size=(1, 25), activation=None)(model_input)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "    # sceond convolution layer\n",
    "    model_output = Conv2D(3, (1, 1), activation=None)(model_output)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "    # pooling layer\n",
    "    model_output = AveragePooling2D(pool_size=(1000, 1))(model_output)\n",
    "    model_output = Flatten()(model_output)\n",
    "\n",
    "    # Dense layer\n",
    "    model_output = Dense(3, activation=None)(model_output)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"relu\")(model_output)\n",
    "\n",
    "    # output layer\n",
    "    model_output = Dense(1, activation=None)(model_output)\n",
    "    model_output = BatchNormalization()(model_output)\n",
    "    model_output = Activation(\"sigmoid\")(model_output)\n",
    "    \n",
    "    model = Model(model_input, model_output)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    for i in list(range(4, 7))+list(range(8, 12)):\n",
    "        model.layers[i].set_weights(ori_model.layers[i].get_weights())\n",
    "        model.layers[i].trainable = False\n",
    "    \n",
    "    \n",
    "#     for idx, layer in enumerate(model.layers):\n",
    "#         print(idx, layer.name, layer.trainable)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()\n",
    "\n",
    "def plot_history(history, path):\n",
    "    \"\"\"\n",
    "    Plot keras training history\n",
    "    :param history: keras history\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 7))\n",
    "\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('model acc')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('model loss')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    plt.savefig(path)\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "print('Running')\n",
    "for fidx in range(0, 5):\n",
    "    print('===============Training Fold {}==============='.format(fidx))\n",
    "    \n",
    "    '''################################# Load Data #################################'''\n",
    "    X_train = np.load('data_folds_raw/X_train_{}_arsinh.npy'.format(fidx))\n",
    "    X_val = np.load('data_folds_raw/X_val_{}_arsinh.npy'.format(fidx))\n",
    "    \n",
    "    # X_train = np.load('data_folds_raw/X_train_{}_norm.npy'.format(fidx))\n",
    "    # X_val = np.load('data_folds_raw/X_val_{}_norm.npy'.format(fidx))\n",
    "    \n",
    "    y_train = np.load('data_folds_raw/y_train_{}.npy'.format(fidx))\n",
    "    y_val = np.load('data_folds_raw/y_val_{}.npy'.format(fidx))\n",
    "    score_train = np.load('data_folds_raw/score_train_{}.npy'.format(fidx))\n",
    "    score_val = np.load('data_folds_raw/score_val_{}.npy'.format(fidx))\n",
    "    covar_train = np.load('data_folds_raw/covar_train_{}_norm.npy'.format(fidx))\n",
    "    covar_val = np.load('data_folds_raw/covar_val_{}_norm.npy'.format(fidx))\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "    covar_train = covar_train.reshape(covar_train.shape[0], covar_train.shape[1], 1)\n",
    "    covar_val = covar_val.reshape(covar_val.shape[0], covar_val.shape[1], 1)\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "    y_val = y_val.reshape(y_val.shape[0], 1)\n",
    "    score_train = score_train.reshape(score_train.shape[0], 1)\n",
    "    score_val = score_val.reshape(score_val.shape[0], 1)\n",
    "\n",
    "    print(X_train.shape, '<->', np.unique(y_val, return_counts=True))\n",
    "\n",
    "    covar_train = covar_train.reshape(covar_train.shape[0], covar_train.shape[1])\n",
    "    covar_val = covar_val.reshape(covar_val.shape[0], covar_val.shape[1])\n",
    "    \n",
    "    \n",
    "    print(X_train[0].shape)\n",
    "    ori_model = original_model()\n",
    "    cur_model = current_model(ori_model)\n",
    "    \n",
    "    del ori_model\n",
    "    gc.collect()\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1, mode='min')\n",
    "    mcp_save = ModelCheckpoint(\n",
    "        '/mnt/Dev_ssd/Dev_ssd/hiv_brain/classification_checkpoints/{}.h5'.format(fidx), save_best_only=True,\n",
    "        monitor='val_loss', mode='min'\n",
    "    )\n",
    "    hist = cur_model.fit(\n",
    "        [X_train, covar_train],\n",
    "        y_train,\n",
    "        epochs=500,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        validation_data=([X_val, covar_val], y_val),\n",
    "        validation_batch_size=32,\n",
    "        callbacks=[ClearMemory(), mcp_save]\n",
    "    )\n",
    "    # plot_history(hist, '/mnt/Dev_ssd/Dev_ssd/hiv_brain/classification_model_checkpoints/{}.jpg'.format(fidx))\n",
    "    \n",
    "    accs.append(max(hist.history['val_accuracy']))\n",
    "\n",
    "    del X_train\n",
    "    del X_val\n",
    "    del y_train\n",
    "    del y_val\n",
    "    del score_train\n",
    "    del score_val\n",
    "    del hist\n",
    "    gc.collect()\n",
    "\n",
    "print(accs)\n",
    "print(sum(accs) / len(accs), (max(accs) - min(accs) )/ 2, np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3e48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
