{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8942d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-2idk07b7 because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import gc\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRFRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from lightgbm import LGBMModel,LGBMClassifier\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4394e2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 10) (60,) (array([0, 1]), array([12,  4]))\n",
      "0.7833333333333333 0.6875 0.8125 0.6153846153846153 \n",
      "\n",
      "(61, 10) (61,) (array([0, 1]), array([8, 7]))\n",
      "0.8032786885245902 0.6 0.46428571428571425 0.5714285714285714 \n",
      "\n",
      "(61, 10) (61,) (array([0, 1]), array([10,  5]))\n",
      "0.7213114754098361 0.6666666666666666 0.74 0.4444444444444445 \n",
      "\n",
      "(61, 10) (61,) (array([0, 1]), array([10,  5]))\n",
      "0.7704918032786885 0.7333333333333333 0.7000000000000001 0.6 \n",
      "\n",
      "(61, 10) (61,) (array([0, 1]), array([10,  5]))\n",
      "0.7868852459016393 0.7333333333333333 0.8 0.6 \n",
      "\n",
      "0.6841666666666667\n",
      "0.7033571428571429\n",
      "0.5662515262515262 0.06253918193194598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# clf = SVC(kernel='sigmoid', random_state=42, probability=True, C=0.1, class_weight='balanced')\n",
    "clf = LogisticRegression(solver='sag', random_state=42, class_weight='balanced')\n",
    "# clf = XGBClassifier(\n",
    "#         random_state = 42,\n",
    "#         objective='binary:logistic',\n",
    "#         n_estimators=500,\n",
    "#         learning_rate=1e-3,\n",
    "#         max_depth=3,\n",
    "#         subsample=0.7,\n",
    "#         scale_pos_weight=np.unique(y_train, return_counts=True)[1][0] / np.unique(y_train, return_counts=True)[1][1]\n",
    "#     )\n",
    "    \n",
    "\n",
    "val_evals = []\n",
    "aucs = []\n",
    "f1s = []\n",
    "for fidx in range(5):\n",
    "    X_train = np.load('/work/zg78/som_folds/CSF_X_train_{}.npy'.format(fidx))\n",
    "    y_train = np.load('/work/zg78/som_folds/CSF_y_train_{}.npy'.format(fidx))\n",
    "    X_val = np.load('/work/zg78/som_folds/CSF_X_val_{}.npy'.format(fidx))\n",
    "    y_val = np.load('/work/zg78/som_folds/CSF_y_val_{}.npy'.format(fidx))\n",
    "    \n",
    "    print(X_train.shape, y_train.shape, np.unique(y_val, return_counts=True))\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(X_train)\n",
    "    X_train = std_scaler.transform(X_train)\n",
    "    X_val = std_scaler.transform(X_val)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = metrics.accuracy_score(y_train, clf.predict(X_train))\n",
    "    val_acc = metrics.accuracy_score(y_val, clf.predict(X_val))\n",
    "    val_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_proba)\n",
    "    f1 = metrics.f1_score(y_val, clf.predict(X_val))\n",
    "    val_evals.append(val_acc)\n",
    "    aucs.append(auc)\n",
    "    f1s.append(f1)\n",
    "    print(train_acc, val_acc, auc, f1, '\\n')\n",
    "    \n",
    "print(sum(val_evals) / len(val_evals))\n",
    "print(sum(aucs) / len(aucs))\n",
    "print(sum(f1s) / len(f1s), np.std(f1s))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff7cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833333333333333 0.6875 0.8125 0.6153846153846153 \n",
      "\n",
      "0.8032786885245902 0.6 0.46428571428571425 0.5714285714285714 \n",
      "\n",
      "0.7049180327868853 0.6 0.7 0.4000000000000001 \n",
      "\n",
      "0.7704918032786885 0.7333333333333333 0.7000000000000001 0.6 \n",
      "\n",
      "0.8032786885245902 0.7333333333333333 0.78 0.6 \n",
      "\n",
      "0.6708333333333334\n",
      "0.6913571428571428\n",
      "0.5573626373626374 0.0799540986539088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# clf = SVC(kernel='sigmoid', random_state=42, probability=True, C=0.1, class_weight='balanced')\n",
    "clf = LogisticRegression(solver='sag', random_state=42, class_weight='balanced')\n",
    "# clf = XGBClassifier(\n",
    "#         random_state = 42,\n",
    "#         objective='binary:logistic',\n",
    "#         n_estimators=500,\n",
    "#         learning_rate=1e-3,\n",
    "#         max_depth=3,\n",
    "#         subsample=0.7,\n",
    "#         scale_pos_weight=np.unique(y_train, return_counts=True)[1][0] / np.unique(y_train, return_counts=True)[1][1]\n",
    "#     )\n",
    "    \n",
    "\n",
    "val_evals = []\n",
    "aucs = []\n",
    "f1s = []\n",
    "\n",
    "for fidx in range(5):\n",
    "    X_train = np.load('/work/zg78/som_folds/CSF_X_train_{}.npy'.format(fidx))\n",
    "    y_train = np.load('/work/zg78/som_folds/CSF_y_train_{}.npy'.format(fidx))\n",
    "    X_val = np.load('/work/zg78/som_folds/CSF_X_val_{}.npy'.format(fidx))\n",
    "    y_val = np.load('/work/zg78/som_folds/CSF_y_val_{}.npy'.format(fidx))\n",
    "        \n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(X_train)\n",
    "    X_train = std_scaler.transform(X_train)\n",
    "    X_val = std_scaler.transform(X_val)\n",
    "    selector = RFE(clf, n_features_to_select=8, step=1)\n",
    "#     clf.fit(X_train, y_train)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = metrics.accuracy_score(y_train, selector.predict(X_train))\n",
    "    val_acc = metrics.accuracy_score(y_val, selector.predict(X_val))\n",
    "    val_proba = selector.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_proba)\n",
    "    f1 = metrics.f1_score(y_val, selector.predict(X_val))\n",
    "    val_evals.append(val_acc)\n",
    "    aucs.append(auc)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(train_acc, val_acc, auc, f1, '\\n')\n",
    "    \n",
    "print(sum(val_evals) / len(val_evals))\n",
    "print(sum(aucs) / len(aucs))\n",
    "print(sum(f1s) / len(f1s), np.std(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f18711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
